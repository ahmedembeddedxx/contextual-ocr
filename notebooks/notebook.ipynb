{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da70a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fitz\n",
    "#!pip install pymupdf pytesseract pillow\n",
    "#!pip install easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e6098d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pytesseract\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import io\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "505a8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualOCR:\n",
    "    def __init__(self, pdf_path):\n",
    "        \"\"\"\n",
    "        Initialize the OCR system with a PDF file.\n",
    "        :param pdf_path: Path to the input PDF file.\n",
    "        \"\"\"\n",
    "        self.pdf_path = pdf_path\n",
    "        self.images = self._pdf_to_images()\n",
    "        self.text_data = []\n",
    "    \n",
    "    def _pdf_to_images(self):\n",
    "        \"\"\"\n",
    "        Convert the PDF pages to images.\n",
    "        :return: List of images extracted from the PDF.\n",
    "        \"\"\"\n",
    "        pdf_document = fitz.open(self.pdf_path)\n",
    "        images = []\n",
    "        \n",
    "        for page_num in range(len(pdf_document)):\n",
    "            page = pdf_document[page_num]\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.open(io.BytesIO(pix.tobytes()))\n",
    "            images.append(img)\n",
    "        \n",
    "        return images\n",
    "    \n",
    "    def _extract_text_ocr(self):\n",
    "        \"\"\"\n",
    "        Perform OCR on extracted images to get text.\n",
    "        :return: List of extracted text from each page.\n",
    "        \"\"\"\n",
    "        text_data = []\n",
    "        print(\"Extracting text using OCR!!\")\n",
    "        for img in self.images:\n",
    "            text = pytesseract.image_to_string(img)\n",
    "            text_data.append(text)\n",
    "        return text_data\n",
    "    \n",
    "    def _clean_text(self, string):\n",
    "        if type(string) != str:\n",
    "            string = str(string)\n",
    "        print(\"Cleaning text!!\")\n",
    "        return string.rstrip(' \\n')\n",
    "\n",
    "    def _extract_text(self):\n",
    "\n",
    "        some_text = self._extract_text_ocr()\n",
    "        client = OpenAI(\n",
    "            base_url=\"https://huggingface.co/api/inference-proxy/together\",\n",
    "            api_key=\"\" #API KEY\n",
    "        )\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'''\n",
    "                The following text ({some_text}) has been extracted from a PDF named \"{path}\" using PyTesseract.  \n",
    "                Due to OCR inaccuracies, the extracted text may contain errors such as misspellings, missing words, incorrect formatting, or garbled content.  \n",
    "\n",
    "                Your task:\n",
    "                - Analyze the text and extract all the questions that are present in it.  \n",
    "                - Identify the topic of the text.  \n",
    "                - Return the results in a CSV format where each row contains the topic and a question found in the text.  \n",
    "                - Do NOT refine or alter the text.  \n",
    "                - Do NOT add any commentary, explanations, or labels—just return the CSV.  \n",
    "                - The format should be: `topic,question`.\n",
    "\n",
    "                Now, extract the questions and the topic in CSV format:  \n",
    "                '''\n",
    "            }\n",
    "        ]\n",
    "        print(\"Refining text using DeepSeek!!\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"deepseek-ai/DeepSeek-R1\", \n",
    "            messages=messages, \n",
    "            max_tokens=1500\n",
    "        )\n",
    "        \n",
    "        return self._clean_text(str(completion.choices[0].message).split('</think>')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aafd841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text using OCR!!\n",
      "Refining text using DeepSeek!!\n"
     ]
    }
   ],
   "source": [
    "path = \"AI Exam.pdf\"\n",
    "ocr = ContextualOCR(f\"../pdf/{path}\")\n",
    "some_text = ocr._extract_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49a770da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\n\\\\ntopic,question\\\\n\"Search Algorithms (BFS + A*)\",\"Problem 1 [BFS +A 7] 17 points}\\\\\\\\n\\\\\\\\nConsider the search space below, where Sis the start node and and\\\\\\\\n\\\\\\\\nGre goal nodes.\\\\\\\\nAres are labeled withthe value ofa cos function; the number gives the cost of traversing the ac\\\\\\\\n\\\\\\\\n‘Along each node isthe valu of a heuristic funtion; the number gives the estimate ofthe distance othe goal\\\\\\\\nAssume that uninformed seach algorithms always choose the lef branch fist when there isa choice.\\\\\\\\n\\\\\\\\nAlso assume that the algorithms do not Keep tack of and recognize repeated stats.\\\\\\\\n\\\\\\\\nQos sue\\\\\\\\n@ v=: 500\\\\\\\\n\\\\\\\\n12 Heursc estimate\\\\\\\\n\\\\\\\\nFor each ofthe following seach suategis:\\\\\\\\n\\\\\\\\n‘What path would be found by the algorithm\\\\\\\\n‘+ Listin omer, al the states that are popped off the OPEN lis. (Sequence of path)\\\\\\\\n‘+ Nodes in the Fringe when the goal was found\\\\\\\\n\\\\\\\\noer [+1 +1 Points}\\\\\\\\n\\\\\\\\noar [24141 Pains\"\\\\n\"Search Algorithms (DFS)\",\"Problem\\', refusal=None, role=\\'assistant\\', audio=None, function_call=None, tool_calls=[])'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a413348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
